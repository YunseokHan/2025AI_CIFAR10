# CIFARâ€‘10 Corrupted Image Classification with ResNetâ€‘50

This repository provides a **single, reproducible pipeline** for measuring how a vanilla ResNetâ€‘50 reacts to three canonical dataâ€“label corruptions on CIFARâ€‘10:

| Variant                | What changes?                                     | Config file                       |
| ---------------------- | ------------------------------------------------- | --------------------------------- |
| **Baseline**           | Nothing â€“ clean i.i.d. data                       | `experiments/baseline.yaml`       |
| **InputÂ Perturbation** | Blurâ†’Sharpen transform applied to *inputs only*   | `experiments/input_perturb.yaml`  |
| **LabelÂ Noiseâ€¯(20â€¯%)** | 20â€¯% of training labels flipped to a random class | `experiments/label_noise20.yaml`  |
| **RandomÂ Shuffle**     | 100â€¯% of training labels uniformly shuffled       | `experiments/random_shuffle.yaml` |

Training all four variants (50â€¯epochs each) takes **â‰ˆâ€¯70â€¯min on a single NVIDIAÂ A100**.

---

## ğŸ“‘Â QuickÂ start

```bash
# Clone & create env (optional)
git clone https://github.com/YunseokHan/2025AI_CIFAR10.git
cd 2025AI_CIFAR10
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt  # torch, torchvision, pyyaml, etc.
```

### 1. Train

`train.sh` launches the four experiments with identical hyperâ€‘parameters (Adam, lrâ€¯=â€¯1eâ€‘4, batchâ€¯128).

```bash
bash train.sh           # ~70â€¯min wallâ€‘clock on A100; creates results/<tag>/
```

### 2. Evaluate & plot

`evaluate.sh` loads the best checkpoint for each tag, computes confusion matrices / perâ€‘class accuracy, and writes summary figures.

```bash
bash evaluate.sh        # produces results/<tag>/{confusion.png,class_acc.csv}
```

Generated artefacts â€“ including **valâ€‘loss log**, **confusionÂ matrices**, and **entropy statistics** â€“ are stored under `results/` and referenced by the accompanying LaTeX report.

---

## ğŸ—‚Â Repository layout

```
experiments/   # YAML configs (one per variant)
  baseline.yaml
  input_perturb.yaml
  label_noise20.yaml
  random_shuffle.yaml
src/
  datasets.py  # CIFAR10Variant loader (noise / shuffle / perturb)
  models.py    # ResNetâ€‘50 w/ CIFAR stem tweak
  train.py     # training loop + valâ€‘loss checkpointing
  evaluate.py  # confusion matrix, classâ€‘acc, entropy
train.sh       # bash helper â€“ runs 4Ã— train.py
evaluate.sh    # bash helper â€“ runs 4Ã— evaluate.py
results/       # logs & figures will appear here after running scripts
report/        # CVPRâ€‘style LaTeX paper (compile w/ latexmk)
```

---

## âš™ï¸Â train.sh

```bash
#!/usr/bin/env bash
set -e
for cfg in experiments/*.yaml; do
  echo "=== Training $cfg ==="
  python src/train.py --config "$cfg"
done
```

## âš™ï¸Â evaluate.sh

```bash
#!/usr/bin/env bash
set -e
for tag in baseline input_perturb label_noise20 random_shuffle; do
  echo "=== Evaluating $tag ==="
  python src/evaluate.py --tag "$tag"
done
```

---

## Reproducing paper figures

After `evaluate.sh`, run the notebook `notebooks/make_plots.ipynb` (or `analysis.py`) to regenerate:

* Accuracyâ€‘vsâ€‘epoch curves
* Final accuracy bar chart (Fig.
* 2Ã—2 confusionâ€‘matrix grid (Fig.
* Entropy table (Tab.

Paths in the notebook assume the default `results/` structure.

---

## Citation

If you find this scaffold useful, please cite the accompanying report:

```bibtex
@misc{han2025cifar10corrupt,
  title   = {Revisiting CIFARâ€‘10 Robustness with Unified Corruptions},
  author  = {Yunseok Han},
  year    = {2025},
  url     = {https://github.com/YunseokHan/2025AI_CIFAR10}
}
```

---

## License

MITÂ License.  See `LICENSE` for details.
